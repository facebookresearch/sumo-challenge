<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Participate in the SUMO Challenge · SUMO: The Scene Understanding and Modeling Challenge</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="## Tracks"/><meta property="og:title" content="Participate in the SUMO Challenge · SUMO: The Scene Understanding and Modeling Challenge"/><meta property="og:type" content="website"/><meta property="og:url" content="https://facebookresearch.github.io/sumo-challenge/index.html"/><meta property="og:description" content="## Tracks"/><meta property="og:image" content="https://facebookresearch.github.io/sumo-challenge/img/docusaurus.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://facebookresearch.github.io/sumo-challenge/img/docusaurus.png"/><link rel="shortcut icon" href="/sumo-challenge/img/favicon.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://facebookresearch.github.io/sumo-challenge/blog/atom.xml" title="SUMO: The Scene Understanding and Modeling Challenge Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://facebookresearch.github.io/sumo-challenge/blog/feed.xml" title="SUMO: The Scene Understanding and Modeling Challenge Blog RSS Feed"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><link rel="stylesheet" href="/sumo-challenge/css/main.css"/></head><body class="sideNavVisible doc separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/sumo-challenge/"><h2 class="headerTitle">SUMO: The Scene Understanding and Modeling Challenge</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/sumo-challenge/blog" target="_self">News</a></li><li class="siteNavItemActive"><a href="/sumo-challenge/docs/participate.html" target="_self">Participate</a></li><li class=""><a href="/sumo-challenge/docs/dataset.html" target="_self">Dataset</a></li><li class=""><a href="/sumo-challenge/docs/workshop.html" target="_self">Workshop</a></li><li class=""><a href="/sumo-challenge/docs/people.html" target="_self">People</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1>Participate in the SUMO Challenge</h1></header><article><div><span><h2><a class="anchor" aria-hidden="true" id="tracks"></a><a href="#tracks" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Tracks</h2>
<p>The SUMO challenge is organized into three performance tracks based on
the output representation of the scene.  A scene is represented as a
collection of elements, each of which models one object in the scene
(e.g., a wall, the floor, or a chair).  An element is represented in one
of three increasingly descriptive representations: bounding box, voxel
grid, or surface mesh. All aspects of a scene are modeled using the
same representation.</p>
<h3><a class="anchor" aria-hidden="true" id="bounding-box-track"></a><a href="#bounding-box-track" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Bounding Box Track</h3>
<p>In the bounding box track, a scene is represented by a collection of
oriented bounding boxes.  This is similar to the SUN RGB-D Object
Detection Challenge.</p>
<h3><a class="anchor" aria-hidden="true" id="voxel-track"></a><a href="#voxel-track" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Voxel Track</h3>
<p>In the voxel track, a scene is represented by a collection of oriented
voxel grids.</p>
<h3><a class="anchor" aria-hidden="true" id="mesh-track"></a><a href="#mesh-track" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Mesh Track</h3>
<p>In the mesh track, a scene is represented by a collection of textured
surface meshes.</p>
<h2><a class="anchor" aria-hidden="true" id="metrics"></a><a href="#metrics" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Metrics</h2>
<p>The SUMO evaluation metrics focus on the four aspects of the representation: geometry, appearance, semantics, and perceptual (GASP).  These metrics are based on best practices from challenges and peer reviewed papers for related tasks. Geometry encompasses object shape accuracy and pose error, appearance measures diffuse reflection error, semantics captures class label precision, and perceptual metrics measure the accuracy of the model according to human perception.</p>
<h2><a class="anchor" aria-hidden="true" id="prizes"></a><a href="#prizes" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Prizes</h2>
<ul>
<li>1st prize - winner of mesh track: $2,500 in cash + Titan X GPU</li>
<li>2nd prize - winner of voxel track: $2,000 in cash + Titan X GPU</li>
<li>3rd prize - winner of bounding box track: $1,500 in cash + Titan X GPU</li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="how-to-participate"></a><a href="#how-to-participate" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How to Participate</h2>
<ol>
<li>Familiarize yourself with the input and output formats.</li>
<li>Download the SUMO software and the data set</li>
<li>Develop your algorithm.</li>
<li>Submit your results using EvalAI.</li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="software-download"></a><a href="#software-download" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Software Download</h2>
<p>The SUMO Challenge software includes Python code to read the SUMO input format, write the output format, and compute the evaluation metrics for a given scene.  The software is still under development.  It will be made available as open source on Github when the challenge is officially launched in July.</p>
<h2><a class="anchor" aria-hidden="true" id="leaderboard"></a><a href="#leaderboard" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Leaderboard</h2>
<p>Once the challenge is launched, the leaderboard will be hosted by EvalAI.</p>
</span></div></article></div><div class="docs-prevnext"></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#tracks">Tracks</a><ul class="toc-headings"><li><a href="#bounding-box-track">Bounding Box Track</a></li><li><a href="#voxel-track">Voxel Track</a></li><li><a href="#mesh-track">Mesh Track</a></li></ul></li><li><a href="#metrics">Metrics</a></li><li><a href="#prizes">Prizes</a></li><li><a href="#how-to-participate">How to Participate</a></li><li><a href="#software-download">Software Download</a></li><li><a href="#leaderboard">Leaderboard</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="copyright">Copyright © 2018 Facebook, Inc.</section></footer></div></body></html>